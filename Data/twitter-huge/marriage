#### extract tweets about marriage etc.
import json
import ijson
import gensim.downloader as api
import nltk
from nltk.corpus import wordnet

# Load pre-trained Word2Vec model
w2v_model = api.load('fasttext-wiki-news-subwords-300')

# Define keywords
keywords = ["married", "defacto", "divorced", "separated", "widowed", "unmarried"]

# Get similar words to each keyword and concatenate them
similar_words = []
for keyword in keywords:
    similar_words += [word[0] for word in w2v_model.most_similar(keyword)]

# Remove duplicates and print the resulting list
similar_words = list(set(similar_words))

def get_synonyms(words, languages):
    synonyms = []
    for word in words:
        for language in languages:
            synsets = wordnet.synsets(word, lang=language)
            for syn in synsets:
                for lemma in syn.lemmas(lang=language):
                    synonyms.append(lemma.name())
    return synonyms

keywords = ["married", "de facto", "divorced", "separated", "widowed", "never married"]
languages = nltk.corpus.wordnet.langs()
synonyms = get_synonyms(similar_words, languages)

# Remove duplicates and print the resulting list
synonyms = list(set(synonyms))
synonyms += list(set(similar_words) - set(synonyms))
print(synonyms)


marital_data = []
processed_tweets = set()
count = 0

with open('twitter-huge.json', 'r', encoding='utf-8') as f:
    parser = ijson.parse(f)
    is_matching_tweet = False
    for prefix, event, value in parser:
        if prefix.endswith('.tokens') and event == 'string':
            tokens = value
            if any(synonym in value.lower() for synonym in synonyms):
                is_matching_tweet = True
                sentence = value.replace('|', ' ')
                if sentence not in processed_tweets:
                    marital_data.append(sentence)
                    processed_tweets.add(sentence)
                    count += 1
                    print(count)
            else:
                is_matching_tweet = False
        elif is_matching_tweet and prefix.endswith('.tweet.id_str') and event == 'string':
            processed_tweets.add(value)

print("total count:", count)

json_data = json.dumps(marital_data, indent=2)

with open("marriage_twitters_total.json", "w") as f:
    f.write(json_data)
